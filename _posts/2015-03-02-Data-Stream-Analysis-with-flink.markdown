---
layout: post
title: Data Stream Analysis with flink
date: 2015-03-02
categories: flink
---

Recent data streaming example with flink in the blog [post](http://flink.apache.org/news/2015/02/09/streaming-example.html) .

Data analysis with [flink](http://flink.apache.org/), the download and the
documentation can be found [here](http://flink.apache.org/docs/0.8//setup_quickstart.html).

First I followed the documentation and executed the steps described there. This should
leave you with a fodler containing the flink installation and you should have started
the job manager in a window in your browser.

<p><center><img src="{{site.baseurl}}/assets/blog/pictures/flink-frontend.png" style="width:400px;height:230px" alt="flink frontend"></center></p>

As described at the official website, you can create a flink based package by using
maven. (Here I am going to restrict the procedure to scala only. Check out the
official docs, if you want to find out how to use Java.)

{% highlight bash %}
mvn archetype:generate -DarchetypeGroupId=org.apache.flink/ -DarchetypeArtifactId=flink-quickstart-scala -DarchetypeVersion=0.8.1
{% endhighlight %}

You have to choose the groupId, which defines the Id of the package, and the artefactId ("proj"), which defines the name of the folder and the name of the jar. In this case I chose "org.inet.app" and "first-streaming" respectively

Now you can execute the example WordCount that are downloaded with the rest of the
dependencies. It can be compiled with:

{% highlight bash %}
mvn package
{% endhighlight %}

Next you need to start the compiled jar with the flink binary:

{% highlight bash %}
bin/flink run -vc "org.inet.app.WordCount" ../first-streaming/target/first-streaming-1.0-SNAPSHOT.jar
{% endhighlight %}

If everything goes as planned your ouptut should tell you that the job has been
finished.

At this point I wanted to give the [example
code](https://github.com/apache/flink/blob/master/flink-staging/flink-streaming/flink-streaming-examples/src/main/scala/org/apache/flink/streaming/scala/examples/windowing/StockPrices.scala)
from the blog post a try. I downloaded the code file and placed it under src.
Unfortunately I had some issues with the code so I decided to cut it down to the
essentials. A single stream of values comes in, each value is manipulated and the
output is pushed to a log:

{% highlight scala %}
package org.inet.app

import java.util.concurrent.TimeUnit._

import org.apache.flink.streaming.api.scala._
import org.apache.flink.streaming.api.scala.windowing.Delta
import org.apache.flink.streaming.api.windowing.helper.Time
import org.apache.flink.util.Collector

import scala.util.Random

object SimpleStream {

  case class Count(symbol: String, count: Int)

  private var fileOutput: Boolean = false
  private var hostName: String = null
  private var port: Int = 0
  private var outputPath: String = null

  def main(args: Array[String]) {

    if (!parseParameters(args)) {
      return
    }

    val env = StreamExecutionEnvironment.getExecutionEnvironment

    //Read a double from a socket stream and manipulate that value
    val socketStockStream = env.socketTextStream(hostName, port).map(x => {
      changeValue(x.toDouble)
    })
    socketStockStream.print()

    env.execute("SimpleStream")
  }

  def changeValue(varx: Double): Double = {
    varx + 3.5
  }

  private def parseParameters(args: Array[String]): Boolean = {
    if (args.length == 3) {
      fileOutput = true
      hostName = args(0)
      port = args(1).toInt
      outputPath = args(2)
    } else if (args.length == 2) {
      hostName = args(0)
      port = args(1).toInt
    } else {
      System.err.println("Usage: SimpleStream <hostname> <port> [<output path>]")
      return false
    }
    true
  }

}
{% endhighlight %}

The code can be run via the scheduler, and the stream is connected via netcat.
(The GNU netcat did not work for me, so you might want to use the BSD version.) 

In one window:
{% highlight bash %}
bin/flink run -vc "org.inet.app.SimpleStream" ../first-streaming/target/first-streaming-1.0-SNAPSHOT.jar 127.0.0.1 9993
{% endhighlight %}

In the other window:
{% highlight bash %}
nc -kl 9999
> 123
> 33
> 44
{% endhighlight %}

When we take another view at the flink web interface at 
http://localhost:8081/ the interface will have changed changed. You will now find a
graphic visualizing the running job (1) and you will further find a dropdown menu
(2) where you can access the standard output generated by our script.

<p><center><img src="{{site.baseurl}}/assets/blog/pictures/flink-frontend-warrows.png" style="width:400px;height:230px" alt="flink frontend"></center></p>

To move further from here, I advise you to either go deeper into the blog post
discussed here or to go directly to the Flink Streaming [API](http://flink.apache.org/docs/latest/streaming_guide.html) and come up with your own applications!
